{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382b0e9d",
   "metadata": {},
   "source": [
    "Each example is a 150 x 150 x 3 RGB digitized image \n",
    "\n",
    "For more information regarding this dataset see https://zenodo.org/record/7711810#.ZAm3k-zMKEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaaaf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fefe20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2388\\1730868312.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd65bc",
   "metadata": {},
   "source": [
    "### Explore Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./EuroSAT_RGB\"\n",
    "for dir in os.listdir(base_dir):\n",
    "    print(f\"there are {len(os.listdir(os.path.join(base_dir,dir)))} images in {dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e762a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "print(\"Printing random sample images\")\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "index = np.random.randint(0,625)\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "for i, img_path in enumerate(os.listdir(base_dir)):\n",
    "    img_dir = os.path.join(base_dir, img_path)\n",
    "    sample_image = load_img(f\"{os.path.join(img_dir, os.listdir(img_dir)[index])}\")\n",
    "    if i == 0:\n",
    "        # Convert an image into its numpy array representation\n",
    "        sample_array = img_to_array(sample_image)\n",
    "        print(f\"Each image has shape: {sample_array.shape}\")\n",
    "    \n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.title.set_text(img_path)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "    \n",
    "    plt.imshow(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed19d5c",
   "metadata": {},
   "source": [
    "### Split images for validation\n",
    "This function will create a new folder with 500 random images per class for training and another with 125 images per class for validating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b758c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(base_dir, output=\"eurosat_images\", seed=1337, ratio=(.8, 0.2,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06268a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"eurosat_images/train\"\n",
    "validation_dir = r\"eurosat_images/val\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0782367e",
   "metadata": {},
   "source": [
    "#### Data preprocessing\n",
    "Training and validation image data generators\n",
    "Now that the data are split into training and validation sets I will create generators to feed the labelled images to the network.\n",
    "\n",
    "#### Normalization and Augmentation\n",
    "We can also normalize (rescale) the images during this step as well as expand the training set through augmentation to prevent overfitting on the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
    "    \n",
    "    # instantiate the image generator class with normalization and augmentation\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                      rotation_range=40,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True,\n",
    "                                      fill_mode='nearest')\n",
    "    \n",
    "    # now use the flow from directory method\n",
    "    train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                      batch_size=50,\n",
    "                                                      class_mode='categorical',\n",
    "                                                      target_size=(150,150))\n",
    "    \n",
    "    # repeat for validation set, no augmentation necessary\n",
    "    validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "    \n",
    "    validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                                 batch_size=25,\n",
    "                                                                 class_mode='categorical',\n",
    "                                                                 target_size=(150,150),\n",
    "                                                                 shuffle=False)\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b0dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator, validation_generator = train_val_generators(train_dir, validation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4fa551",
   "metadata": {},
   "source": [
    "### Building and compiling the model\n",
    "Now we will build the CNN architecture using the sequential API and compile it with the Adam optimizer and a very small learning rate.\n",
    "\n",
    "- use 3x3 filters for convolving.\n",
    "\n",
    "- use 2x2 for pooling\n",
    "\n",
    "The model initially suffered from underfitting, with high bias resulting in poor training accuracy. To combat this I deepened the network with more convolutional and dense layers, increased the number of neurons in dense layers and trained the model for more epochs.\n",
    "\n",
    "Dropout of 0.1 is used to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5828700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        # first convolution\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # second convolution\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # third convolution\n",
    "        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        # flattening layer\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # dropout to prevent overfitting\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # first dense layer with 256 neurons\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        # second dense layer with 512 neurons\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        # one output layer with 8 neurons (one for each class) and softmax activation for multiclass classification\n",
    "        tf.keras.layers.Dense(8, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                 loss = 'categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e51456",
   "metadata": {},
   "source": [
    "### Training and testing the model accuracy\n",
    "First extend the callback class to create a callback that stops the model training further if 90% validation accuracy has been reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82699faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"val_accuracy\") is not None and logs.get(\"val_accuracy\") > 0.9:\n",
    "            print(\"\\n90% validation accuracy reached, stopping training.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1e49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model and the callback\n",
    "model = create_model()\n",
    "callbacks = myCallback()\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_generator,\n",
    "                   epochs=100,\n",
    "                   validation_data=validation_generator,\n",
    "                   callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4a64d0",
   "metadata": {},
   "source": [
    "### Plot model training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91289fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs=range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e9d3b",
   "metadata": {},
   "source": [
    "Validation accuracy and loss that tracks training accuracy and loss closely is a good sign that we are not suffering from overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4828474",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "lets determine whether the model is good at predicting land use and which classes the model is better/worse at predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f7e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "Y_pred = model.predict(validation_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_test = validation_generator.classes\n",
    "\n",
    "labels = [x[3:] for x in os.listdir(base_dir)]\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "plt.rcParams[\"figure.figsize\"] = (25,5.5)\n",
    "disp.plot(cmap=plt.cm.Blues,xticks_rotation=45)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
